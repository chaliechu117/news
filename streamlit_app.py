# app.py
import streamlit as st
import requests, re, json, math
from bs4 import BeautifulSoup
from huggingface_hub import InferenceClient

st.set_page_config(page_title="ë‰´ìŠ¤ í˜¸ì¬/ì•…ì¬ ë¶„ë¥˜ê¸° â€¢ Llama-2-7b-chat", page_icon="ğŸ¦™")

# -----------------------------
# UI: ì‚¬ì´ë“œë°” ì„¤ì •
# -----------------------------
st.sidebar.header("ëª¨ë¸ ì„¤ì •")
hf_token = st.sidebar.text_input("Hugging Face Access Token", type="password", placeholder="hf_xxx")
model = st.sidebar.text_input("Model Repo", value="meta-llama/Llama-2-7b-chat-hf")
temperature = st.sidebar.slider("temperature", 0.0, 1.0, 0.2, 0.05)
max_new_tokens = st.sidebar.slider("max_new_tokens", 64, 1024, 256, 32)
top_p = st.sidebar.slider("top_p", 0.1, 1.0, 0.9, 0.05)

st.title("ğŸ¦™ Llama-2-7b-chat ë‰´ìŠ¤ í˜¸ì¬/ì•…ì¬ ë¶„ë¥˜ê¸°")

# -----------------------------
# ì…ë ¥ ë°©ì‹ ì„ íƒ: URL ìŠ¤í¬ë© vs ì§ì ‘ ì…ë ¥
# -----------------------------
mode = st.radio("ì…ë ¥ ë°©ì‹ì„ ì„ íƒí•˜ì„¸ìš”", ["ë‰´ìŠ¤ URLë¡œ ìŠ¤í¬ë©", "í…ìŠ¤íŠ¸ ì§ì ‘ ë¶™ì—¬ë„£ê¸°"], horizontal=True)

def fetch_article(url: str) -> str:
    try:
        resp = requests.get(url, timeout=15, headers={"User-Agent": "Mozilla/5.0"})
        resp.raise_for_status()
        html = resp.text
        soup = BeautifulSoup(html, "html.parser")

        # meta/og/ld+jsonì—ì„œ ì œëª©Â·ì„¤ëª… í›„ë³´
        og_desc = soup.find("meta", property="og:description")
        og_title = soup.find("meta", property="og:title")

        # ë³¸ë¬¸ í›„ë³´: article íƒœê·¸, id/classì— article|content í¬í•¨, p íƒœê·¸ ë‹¤ëª¨ìœ¼ê¸°
        candidates = []
        for sel in ["article", "[id*='article']", "[class*='article']", "[id*='content']", "[class*='content']"]:
            for node in soup.select(sel):
                text = " ".join(p.get_text(" ", strip=True) for p in node.find_all(["p","h2","li"]))
                if len(text) > 400:
                    candidates.append(text)

        # ì¼ë°˜ p íƒœê·¸ ë°±ì—… í”Œëœ
        if not candidates:
            pts = " ".join(p.get_text(" ", strip=True) for p in soup.find_all("p"))
            if len(pts) > 400:
                candidates.append(pts)

        bodies = []
        if og_title and og_title.get("content"):
            bodies.append(og_title["content"])
        if og_desc and og_desc.get("content"):
            bodies.append(og_desc["content"])
        if candidates:
            bodies.append(max(candidates, key=len))

        text = "\n\n".join(bodies).strip()
        # ê´‘ê³ /ì¡ìŒ ê°„ë‹¨ ì œê±°
        text = re.sub(r"\s+", " ", text)
        return text
    except Exception as e:
        st.error(f"ìŠ¤í¬ë© ì˜¤ë¥˜: {e}")
        return ""

news_text = ""
if mode == "ë‰´ìŠ¤ URLë¡œ ìŠ¤í¬ë©":
    url = st.text_input("ë‰´ìŠ¤ URL", placeholder="https://...")
    if st.button("ìŠ¤í¬ë© ì‹¤í–‰", type="primary") and url:
        news_text = fetch_article(url)
        if not news_text:
            st.warning("ë³¸ë¬¸ì„ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. í…ìŠ¤íŠ¸ë¥¼ ì§ì ‘ ë¶™ì—¬ë„£ì–´ ì£¼ì„¸ìš”.")
else:
    news_text = st.text_area("ë‰´ìŠ¤ ì›ë¬¸ì„ ë¶™ì—¬ë„£ìœ¼ì„¸ìš”", height=240)

if news_text:
    with st.expander("ì…ë ¥ í…ìŠ¤íŠ¸ í™•ì¸/í¸ì§‘"):
        news_text = st.text_area("í…ìŠ¤íŠ¸", value=news_text, height=240)

# -----------------------------
# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ (Llama-2 Chat ìŠ¤íƒ€ì¼)
# ì¶œë ¥ì€ JSONë§Œ í—ˆìš©
# -----------------------------
def build_prompt(article: str) -> str:
    system = (
        "You are a precise financial news classifier. "
        "Classify whether the news is bullish (í˜¸ì¬), bearish (ì•…ì¬), or neutral for the main involved asset(s). "
        "Return only valid JSON in UTF-8 with keys: "
        "label (one of: bullish, bearish, neutral), "
        "confidence (0~1 float), "
        "summary_ko (<=80ì í•œêµ­ì–´ ìš”ì•½), "
        "reasons_ko (í•œêµ­ì–´ ê·¼ê±° 2~4ê°œ ë¦¬ìŠ¤íŠ¸), "
        "tickers (ê´€ë ¨ ì¢…ëª©/í‹°ì»¤ ë¦¬ìŠ¤íŠ¸, ëª¨ë¥´ê² ìœ¼ë©´ ë¹ˆ ë¦¬ìŠ¤íŠ¸)."
    )
    user = (
        "ì•„ë˜ ë‰´ìŠ¤ì˜ íˆ¬ì ê´€ì  ì„íŒ©íŠ¸ë¥¼ ë¶„ë¥˜í•´ì¤˜. ëª¨í˜¸í•˜ë©´ neutralë¡œ.\n\n"
        f"ë‰´ìŠ¤ ì›ë¬¸:\n{article[:8000]}\n\n"
        "ì¶œë ¥ì€ ì˜¤ì§ JSONë§Œ:\n"
        "{"
        "\"label\":\"bullish|bearish|neutral\","
        "\"confidence\":0.0,"
        "\"summary_ko\":\"...\","
        "\"reasons_ko\":[\"...\"],"
        "\"tickers\":[\"...\"]"
        "}"
    )
    # Llama-2 chat í˜•ì‹
    return f"<s>[INST] <<SYS>>\n{system}\n<</SYS>>\n{user} [/INST]"

def extract_json(text: str):
    try:
        m = re.search(r"\{.*\}", text, flags=re.S)
        if not m:
            return None
        obj = json.loads(m.group(0))
        return obj
    except Exception:
        return None

# -----------------------------
# ë¶„ë¥˜ ì‹¤í–‰
# -----------------------------
def classify(article: str):
    if not hf_token:
        st.warning("ë¨¼ì € Hugging Face í† í°ì„ ì…ë ¥í•˜ì„¸ìš”.")
        return None, None

    client = InferenceClient(model=model, token=hf_token)
    prompt = build_prompt(article)

    # Inference API: text_generation (Llama-2-7b-chat-hf)
    # ì°¸ê³ : ëª¨ë¸/ì—”ë“œí¬ì¸íŠ¸ì— ë”°ë¼ 'stop_sequences'ê°€ í•„ìš”í•  ìˆ˜ ìˆìŒ
    try:
        output = client.text_generation(
            prompt,
            max_new_tokens=max_new_tokens,
            temperature=temperature,
            top_p=top_p,
            do_sample=True,
            repetition_penalty=1.05,
            return_full_text=False,
        )
        parsed = extract_json(output)
        return output, parsed
    except Exception as e:
        st.error(f"Inference ì˜¤ë¥˜: {e}")
        return None, None

run = st.button("ë¶„ë¥˜ ì‹¤í–‰", type="primary", disabled=(not bool(news_text)))
if run and news_text:
    with st.spinner("ë¶„ë¥˜ ì¤‘..."):
        raw, parsed = classify(news_text)

    if parsed is None:
        st.error("JSON íŒŒì‹±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. raw ì¶œë ¥ í™•ì¸ í›„ í”„ë¡¬í”„íŠ¸ë¥¼ ì¡°ì •í•˜ì„¸ìš”.")
        if raw:
            st.code(raw)
    else:
        label = str(parsed.get("label", "neutral")).lower()
        confidence = float(parsed.get("confidence", 0.0))
        summary_ko = parsed.get("summary_ko", "")
        reasons_ko = parsed.get("reasons_ko", [])
        tickers = parsed.get("tickers", [])

        # ë¼ë²¨ ìƒ‰ìƒ
        color = {"bullish": "#0ea5e9", "bearish": "#ef4444", "neutral": "#9ca3af"}.get(label, "#9ca3af")

        st.markdown(
            f"""
            <div style="display:flex;gap:10px;align-items:center;">
              <div style="padding:4px 10px;border-radius:999px;background:{color};color:white;font-weight:600;">
                {label.upper()}
              </div>
              <div style="opacity:0.8;">confidence: {confidence:.2f}</div>
            </div>
            """,
            unsafe_allow_html=True
        )
        if summary_ko:
            st.markdown(f"ìš”ì•½: {summary_ko}")
        if reasons_ko:
            st.markdown("ê·¼ê±°")
            for i, r in enumerate(reasons_ko, 1):
                st.markdown(f"- {i}. {r}")
        if tickers:
            st.markdown(f"ê´€ë ¨ ì¢…ëª©/í‹°ì»¤: {', '.join(tickers)}")

        col1, col2 = st.columns(2)
        with col1:
            st.download_button(
                "JSON ê²°ê³¼ ë‹¤ìš´ë¡œë“œ",
                data=json.dumps(parsed, ensure_ascii=False, indent=2),
                file_name="classification.json",
                mime="application/json",
            )
        with col2:
            st.download_button(
                "Raw ì¶œë ¥ ë‹¤ìš´ë¡œë“œ",
                data=raw if raw else "",
                file_name="raw_output.txt",
                mime="text/plain",
                disabled=(raw is None)
            )

        with st.expander("ì›ë¬¸ í”„ë¡¬í”„íŠ¸ ë³´ê¸°"):
            st.code(build_prompt(news_text))

# -----------------------------
# ì‚¬ìš© íŒ
# -----------------------------
st.caption(
    "íŒ: Llama-2-7b-chatì€ ë¼ì´ì„ ìŠ¤ ìˆ˜ë½ì´ í•„ìš”í•©ë‹ˆë‹¤. Hugging Face ê³„ì •ì—ì„œ í•´ë‹¹ ëª¨ë¸ ì ‘ê·¼ ê¶Œí•œì„ ë°›ì•„ì•¼ Inference API í˜¸ì¶œì´ ì„±ê³µí•©ë‹ˆë‹¤. "
    "ë˜í•œ ë‰´ìŠ¤ ì¶œì²˜/í¬ë§·ì— ë”°ë¼ ìŠ¤í¬ë© ì„±ëŠ¥ì´ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆì–´ìš”."
)
